<!-- <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Detection</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            color: #333;
            margin: 0;
            padding: 20px;
            text-align: center;
        }
        
        h1 {
            color: #2c3e50;
        }

        button {
            background-color: #3498db;
            color: white;
            border: none;
            padding: 10px 20px;
            margin: 10px;
            font-size: 16px;
            cursor: pointer;
            border-radius: 5px;
            transition: background-color 0.3s;
        }

        button:hover {
            background-color: #2980b9;
        }

        .info {
            background-color: #ecf0f1;
            border: 1px solid #bdc3c7;
            padding: 15px;
            border-radius: 5px;
            margin: 20px auto;
            max-width: 500px;
        }

        .info p {
            margin: 0;
        }
    </style>
</head>
<body>
    <h1>Emotion Detection</h1>
    <button id="start-capture">Start Capture</button>
    
    <div class="info">
        <p>When you click "Start Capture," a window will appear in the taskbar. Open it to see the video stream.</p>
        <p>To stop capturing, press the "q" key on your keyboard.</p>
    </div>

    <script>
        document.getElementById('start-capture').onclick = function() {
            // Trigger the capture route
            fetch('/capture')
                .then(response => response.json())
                .then(data => console.log(data));
        };
    </script>
</body>
</html> -->

<!-- 
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Detection</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            color: #333;
            margin: 0;
            padding: 20px;
            text-align: center;
        }
       
         ul {
    list-style-type: none;

}   
        
        
        h1 {
            color: #2c3e50;
        }

        button {
            background-color: #3498db;
            color: white;
            border: none;
            padding: 10px 20px;
            margin: 10px;
            font-size: 16px;
            cursor: pointer;
            border-radius: 5px;
            transition: background-color 0.3s;
        }

        button:hover {
            background-color: #2980b9;
        }

        .info {
            background-color: #ecf0f1;
            border: 1px solid #bdc3c7;
            padding: 15px;
            border-radius: 5px;
            margin: 20px auto;
            max-width: 500px;
        }

        .results {
            margin-top: 20px;
            background-color: #e7f9e7;
            padding: 15px;
            border: 1px solid #c8e6c9;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <h1>Emotion Detection</h1>
    <button id="start-capture">Start Capture</button>
    
    <div class="info">
        <p>When you click "Start Capture," a window will appear in the taskbar. Open it to see the video stream.</p>
        <p>To stop capturing, press the "q" key on your keyboard.</p>
    </div>

    <div class="results" id="results-container"></div>
    <script>
        document.getElementById('start-capture').onclick = function() {
            // Trigger the capture route
            fetch('/capture')
                .then(response => response.json())
                .then(data => {
                    console.log(data);
                    displayResults(data.results); // Call function to display results
                });
        };
    
        function displayResults(results) {
    const resultsContainer = document.getElementById('results-container');
    resultsContainer.innerHTML = ''; // Clear previous results

    if (results.length === 0) {
        resultsContainer.innerHTML = '<p>No results captured.</p>';
        return;
    }

    // Create a list to display all detected labels and corresponding messages
    const messagesList = document.createElement('ul');

    results.forEach((frameResults) => {
        // Extract the label from the frameResults
        const label = frameResults.label; // Assuming frameResults contains an object with a label property
        const message = getEmotionMessage(label); // Get the corresponding message for the emotion

        const listItem = document.createElement('li');
        listItem.textContent = message; // Set the emotional message as the text of the list item
        messagesList.appendChild(listItem); // Add the list item to the messages list
    });

    resultsContainer.appendChild(messagesList); // Append the list to the results container
}


        function getEmotionMessage(emotion) {
    switch (emotion) {
        case 'Happy':
            return 'üòä You seem to be feeling great! Keep smiling!';
        case 'Sad':
            return 'üò¢ It‚Äôs okay to feel sad sometimes. Take care of yourself.';
        case 'Angry':
            return 'üò† Take a deep breath. It‚Äôs important to stay calm.';
        case 'Surprised':
            return 'üòÆ Wow! That‚Äôs quite a surprise! Embrace the unexpected!';
        case 'Fear':
            return 'üò® It‚Äôs normal to feel scared sometimes. Remember, you‚Äôre not alone.';
        case 'Neutral':
            return 'üòê You‚Äôre feeling neutral. A perfect time to reflect!';
        // Add more emotions and phrases as needed
        default:
            return 'ü§î It‚Äôs hard to say how you‚Äôre feeling right now!';
    } }
    </script>
    
</body> -->
<!-- </html> -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Detection from Faces</title>
    <style>
        /* Base styles */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: Arial, sans-serif;
        }

        /* Body styling */
        body {
            background-color: #f3f4f6;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            padding: 20px;
        }

        /* Header styling */
        h1 {
            color: #333;
            font-size: 2em;
            margin-bottom: 20px;
            text-align: center;
        }

        /* Video container */
        .video-container {
            max-width: 720px;
            width: 100%;
            box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.2);
            border-radius: 8px;
            overflow: hidden;
            margin-bottom: 20px;
        }

        video {
            width: 100%;
            height: auto;
            border-radius: 8px;
        }

        /* Description section */
        .description {
            max-width: 720px;
            background: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1);
            color: #444;
            line-height: 1.6;
        }

        .description h2 {
            color: #007acc;
            margin-bottom: 10px;
            font-size: 1.6em;
        }

        .description p {
            font-size: 1em;
            margin-bottom: 10px;
        }

        .highlight {
            color: #007acc;
            font-weight: bold;
        }

        /* Responsive design */
        @media (max-width: 768px) {
            h1 {
                font-size: 1.8em;
            }

            .description {
                padding: 15px;
            }
        }
    </style>
</head>
<body>
    <h1>Emotion Detection from Faces</h1>
    <div class="video-container">
        <video controls>
            <source src="{{ url_for('static', filename='emotion.mp4') }}" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    </div>

    <div class="description">
        <h2>About the Emotion Detection Model</h2>
        <p>The video above demonstrates a <span class="highlight">facial emotion detection model</span> designed to analyze and identify emotions from facial expressions in real-time. This model employs advanced computer vision and deep learning techniques to recognize various emotions based on facial features and movements.</p>
        <p>By processing frames captured by a camera, the model can detect emotions such as happiness, sadness, anger, surprise, and more. It uses a trained neural network to interpret facial landmarks and expressions, allowing for accurate emotion classification.</p>
        <p>This technology is applicable in various fields, including <span class="highlight">mental health assessment, customer feedback analysis, and interactive user experiences</span>. By understanding emotions, systems can adapt responses to enhance user engagement and well-being.</p>
    </div>
</body>
</html>
